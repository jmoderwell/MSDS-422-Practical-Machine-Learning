{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSDS 422 Multi-Class Models: PCA and Random Forests\n",
    "### Assignment 5 (with PCA)\n",
    "### John Moderwell\n",
    "### Introduction:\n",
    "In previous assignments, data from the Boston Housing Study was used to train, test and evaluate regression models as well as decision tree/random forest models. In this assignment, the MNIST dataset will be used for benchmark testing alternative modeling approaches. This will involve random forest classification and principal component analysis (PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed value for random number generators to obtain reproducible results\n",
    "RANDOM_SEED = 1\n",
    "\n",
    "# import base packages \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant Scikit Learn packages\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.decomposition import PCA, FactorAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set working directory\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\R\\\\Desktop\\\\MSDS 422\\\\Assignment 5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "from scipy.io import loadmat\n",
    "mnist_alternative_url = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n",
    "mnist_path = \"./mnist-original.mat\"\n",
    "response = urllib.request.urlopen(mnist_alternative_url)\n",
    "with open(mnist_path, \"wb\") as f:\n",
    "  content = response.read()\n",
    "  f.write(content)\n",
    "  mnist_raw = loadmat(mnist_path)\n",
    "  mnist = {\n",
    "  \"data\": mnist_raw[\"data\"].T,\n",
    "  \"target\": mnist_raw[\"label\"][0],\n",
    "  \"COL_NAMES\": [\"label\", \"data\"],\n",
    "  \"DESCR\": \"mldata.org dataset: mnist-original\",}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8), 'target': array([0., 0., 0., ..., 9., 9., 9.]), 'COL_NAMES': ['label', 'data'], 'DESCR': 'mldata.org dataset: mnist-original'}\n"
     ]
    }
   ],
   "source": [
    "#examine dataset\n",
    "print(mnist)\n",
    "\n",
    "#create exaplanatory and response variables\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Structure of explanatory variable: (70000, 784)\n",
      "\n",
      " Structure of response: (70000,)\n"
     ]
    }
   ],
   "source": [
    "#take a closer look at structure of data\n",
    "print('\\n Structure of explanatory variable:', X.shape)\n",
    "print('\\n Structure of response:', y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Principal Component Analysis (PCA) \n",
    "Identify optimal number of components for model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- Principal Component Analysis -----\n",
      "\n",
      "PCA on full 70000 dataset took 6.66s\n",
      "PCA number of components: 154\n"
     ]
    }
   ],
   "source": [
    "#PCA\n",
    "print('')\n",
    "print('----- Principal Component Analysis -----')\n",
    "print('')\n",
    "#See how many components should be included in PCA reduced dataset\n",
    "#See how long it takes \n",
    "t0=time.time()\n",
    "pca_data = X\n",
    "pca = PCA(n_components=0.95)\n",
    "X_reduced = pca.fit_transform(pca_data)\n",
    "t1=time.time()\n",
    "print(\"PCA on full 70000 dataset took {:.2f}s\".format(t1 - t0))\n",
    "print('PCA number of components:',pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Explained Variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>154.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.006171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.013253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.001579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.004761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.097461</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Explained Variance\n",
       "count          154.000000\n",
       "mean             0.006171\n",
       "std              0.013253\n",
       "min              0.000449\n",
       "25%              0.000752\n",
       "50%              0.001579\n",
       "75%              0.004761\n",
       "max              0.097461"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#examine explained variance\n",
    "pca_explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "explained_variance = pd.DataFrame(pca_explained_variance, columns=['Explained Variance'])\n",
    "\n",
    "explained_variance.describe().round(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier with PCA (154 variables)\n",
    "Assess classification performance using 154 variables and evaluating with F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use components and find train and test sets\n",
    "principalDf = pd.DataFrame(data = mnist_X_reduced)\n",
    "# Only the explanatory variables were used for PCA, therefore, y tables remain the same\n",
    "x_train = principalDf[0:59999]\n",
    "x_test = principalDf[60000:69999]\n",
    "y_train = y[0:59999,]\n",
    "y_test = y[60000:69999,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classification on reduced dataset (154 components): 8.53s\n",
      "F1 Score: 0.8980761888146362\n"
     ]
    }
   ],
   "source": [
    "# Fit Random Forest model\n",
    "#See how long it takes to evaluate reduced dataset using using RF model\n",
    "t0=time.time()\n",
    "rf = RandomForestClassifier(random_state = 9999, n_estimators=10, bootstrap=True\n",
    ", max_features='sqrt')\n",
    "model = rf.fit(x_train, y_train)\n",
    "# Calculate predictions\n",
    "y_predict = model.predict(x_test)\n",
    "# Calculate F1 score\n",
    "# Ideal value is 1\n",
    "f1 = f1_score(y_test, y_predict, average='weighted')\n",
    "t1=time.time()\n",
    "print(\"Random Forest classification on reduced dataset (154 components): {:.2f}s\".format(t1 - t0))\n",
    "print('F1 Score:',f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Performing a principal component analysis on the data had a significant effect on the time it took to evaluate data using a random forest model. The total time it took to identify the principal components (154) and then build, fit and evaluate the model was approximately 15.13 seconds. The F1 score was .89807. On the other hand, building, fitting and evaluating the RF model on the entire dataset took 315.94 seconds (approximately 21x longer). The F1 score .97158. As we can see, there is a trade off between efficiency and accuracy. While a PCA reduced dataset takes less time to evaluate, it results in a less accurate score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
