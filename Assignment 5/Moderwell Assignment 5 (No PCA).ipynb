{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MSDS 422 Multi-Class Models: PCA and Random Forests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5 (No PCA)\n",
    "### John Moderwell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction:\n",
    "In previous assignments, data from the Boston Housing Study was used to train, test and evaluate regression models as well as decision tree/random forest models. In this assignment, the MNIST dataset will be used for benchmark testing alternative modeling approaches. This will involve random forest classification and principal component analysis (PCA)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed value for random number generators to obtain reproducible results\n",
    "RANDOM_SEED = 1\n",
    "\n",
    "# import base packages \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant Scikit Learn packages\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set working directory\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\R\\\\Desktop\\\\MSDS 422\\\\Assignment 5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from six.moves import urllib\n",
    "from sklearn.datasets import fetch_mldata\n",
    "\n",
    "from scipy.io import loadmat\n",
    "mnist_alternative_url = \"https://github.com/amplab/datascience-sp14/raw/master/lab7/mldata/mnist-original.mat\"\n",
    "mnist_path = \"./mnist-original.mat\"\n",
    "response = urllib.request.urlopen(mnist_alternative_url)\n",
    "with open(mnist_path, \"wb\") as f:\n",
    "  content = response.read()\n",
    "  f.write(content)\n",
    "  mnist_raw = loadmat(mnist_path)\n",
    "  mnist = {\n",
    "  \"data\": mnist_raw[\"data\"].T,\n",
    "  \"target\": mnist_raw[\"label\"][0],\n",
    "  \"COL_NAMES\": [\"label\", \"data\"],\n",
    "  \"DESCR\": \"mldata.org dataset: mnist-original\",}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       ...,\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0],\n",
      "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8), 'target': array([0., 0., 0., ..., 9., 9., 9.]), 'COL_NAMES': ['label', 'data'], 'DESCR': 'mldata.org dataset: mnist-original'}\n"
     ]
    }
   ],
   "source": [
    "#examine dataset\n",
    "print(mnist)\n",
    "\n",
    "#create exaplanatory and response variables\n",
    "X, y = mnist['data'], mnist['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Structure of explanatory variable: (70000, 784)\n",
      "\n",
      " Structure of response: (70000,)\n"
     ]
    }
   ],
   "source": [
    "#take a closer look at structure of data\n",
    "print('\\n Structure of explanatory variable:', X.shape)\n",
    "print('\\n Structure of response:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data is to be trained on 60,000 observations and tested on remaining 10,000\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequency distribution for 60,000 observations (for model building)\n",
      "5.0    5421\n",
      "4.0    5842\n",
      "8.0    5851\n",
      "6.0    5918\n",
      "0.0    5923\n",
      "9.0    5948\n",
      "2.0    5958\n",
      "3.0    6131\n",
      "7.0    6265\n",
      "1.0    6742\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#observe frequency distribution for training set (first 60,000 observations)\n",
    "mnist_y_0_59999_df = pd.DataFrame({'label': y[0:59999,]}) \n",
    "print('\\nFrequency distribution for 60,000 observations (for model building)')\n",
    "print(mnist_y_0_59999_df['label'].value_counts(ascending = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frequency distribution for last 10,000 observations (holdout sample)\n",
      "5.0     892\n",
      "6.0     958\n",
      "8.0     974\n",
      "0.0     980\n",
      "4.0     982\n",
      "9.0    1008\n",
      "3.0    1010\n",
      "7.0    1028\n",
      "2.0    1032\n",
      "1.0    1135\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#observe frequency distribution for test set (last 10,000 observations)\n",
    "mnist_y_60000_69999_df = pd.DataFrame({'label': y[60000:69999,]}) \n",
    "print('\\nFrequency distribution for last 10,000 observations (holdout sample)')\n",
    "print(mnist_y_60000_69999_df['label'].value_counts(ascending = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier (all variables)\n",
    "Assess classification performance using all 784 variables and evaluating with F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "shuffle_index = np.random.permutation(60000)\n",
    "X_train, y_train = X_train[shuffle_index], y_train[shuffle_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest classification on full dataset took 315.51s\n",
      "F1 Score: 0.9722867467081924\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Fit Random Forest Classifier to full dataset and then evaluate on test set\n",
    "#See how long it takes to evaluate entire dataset using RF model\n",
    "t0=time.time()\n",
    "clf = RandomForestClassifier(n_estimators=784, random_state = 9999, bootstrap = True)\n",
    "model = clf.fit(X_train, y_train)\n",
    "\n",
    "# Calculate predictions\n",
    "y_predict = model.predict(X_test)\n",
    "\n",
    "# Calculate F1 score\n",
    "# Ideal value is 1\n",
    "f1 = f1_score(y_test, y_predict, average='weighted')\n",
    "t1=time.time()\n",
    "\n",
    "print(\"Random Forest classification on full dataset took {:.2f}s\".format(t1 - t0))\n",
    "print('F1 Score:',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
